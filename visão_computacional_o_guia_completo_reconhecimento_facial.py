# -*- coding: utf-8 -*-
"""Visão Computacional: O Guia Completo - Reconhecimento Facial.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BFOYVC_VcDPLypxrBqV2_Dw6yOauniVx

# Visão Computacional: O Guia Completo - Reconhecimento Facial

# OpenCV

## Carregamento da base de dados

- Yale faces database: http://vision.ucsd.edu/content/yale-face-database
"""

from PIL import Image
import cv2
import numpy as np
from google.colab.patches import cv2_imshow
from google.colab import drive
drive.mount('/content/drive')

import zipfile
path = '/content/drive/MyDrive/Cursos - recursos/Visão Computacional Guia Completo/Datasets/yalefaces.zip'
zip_object = zipfile.ZipFile(file=path, mode = 'r')
zip_object.extractall('./')
zip_object.close()

"""## Pré-processamento das imagens"""

import os
print(os.listdir('/content/yalefaces/train'))

def get_image_data():
  paths = [os.path.join('/content/yalefaces/train', f) for f in os.listdir('/content/yalefaces/train')]
  #print(paths)
  faces = []
  ids = []
  for path in paths:
    #print(path)
    imagem = Image.open(path).convert('L')
    #print(type(imagem))
    imagem_np = np.array(imagem, 'uint8')
    #print(type(imagem_np))
    #print(os.path.split(path)[1])
    id = int(os.path.split(path)[1].split('.')[0].replace('subject', ''))
    #print(id)
    ids.append(id)
    faces.append(imagem_np)
    
  return np.array(ids), faces

ids, faces = get_image_data()

ids

len(ids)

len(faces)

faces[1], faces[1].shape

ids[1]

243 * 320, 243 * 320 * 3

"""## Treinamento do classificador LBPH"""

8 * 8, 9 * 9

# threshold: 1.7976931348623157e+308
# radius: 1
# neighbors: 8
# grid_x: 8
# grid_y: 8

lbph_classifier = cv2.face.LBPHFaceRecognizer_create(radius=4, neighbors=14,grid_x=9,grid_y=9)
lbph_classifier.train(faces, ids)
lbph_classifier.write('lbph_classifier.yml')

"""## Reconhecimento de faces"""

lbph_face_classifier = cv2.face.LBPHFaceRecognizer_create()
lbph_face_classifier.read('/content/lbph_classifier.yml')

imagem_teste = '/content/yalefaces/test/subject10.sad.gif'

imagem = Image.open(imagem_teste).convert('L')
imagem_np = np.array(imagem, 'uint8')
imagem_np

imagem_np.shape

previsao = lbph_face_classifier.predict(imagem_np)
previsao

previsao[0]

saida_esperada = int(os.path.split(imagem_teste)[1].split('.')[0].replace('subject', ''))
saida_esperada

cv2.putText(imagem_np, 'Pred: ' + str(previsao[0]), (10,30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))
cv2.putText(imagem_np, 'Exp: ' + str(saida_esperada), (10,50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))
cv2_imshow(imagem_np)

"""## Avaliação do classificador"""

paths = [os.path.join('/content/yalefaces/test', f) for f in os.listdir('/content/yalefaces/test')]
previsoes = []
saidas_esperadas = []
for path in paths:
  #print(path)
  imagem = Image.open(path).convert('L')
  imagem_np = np.array(imagem, 'uint8')
  previsao, _ = lbph_face_classifier.predict(imagem_np)
  #print(previsao)
  saida_esperada = int(os.path.split(path)[1].split('.')[0].replace('subject', ''))
  #print(saida_esperada)

  previsoes.append(previsao)
  saidas_esperadas.append(saida_esperada)

type(previsoes), type(saidas_esperadas)

previsoes = np.array(previsoes)
saidas_esperadas = np.array(saidas_esperadas)

type(previsoes), type(saidas_esperadas)

previsoes

saidas_esperadas

from sklearn.metrics import accuracy_score
accuracy_score(saidas_esperadas, previsoes)

len(previsoes)

(30 * 70) / 100

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(saidas_esperadas, previsoes)
cm

import seaborn
seaborn.heatmap(cm, annot=True);

"""# Dlib"""

import dlib

"""## Detecção de pontos faciais"""

detector_face = dlib.get_frontal_face_detector()
detector_pontos = dlib.shape_predictor('/content/drive/MyDrive/Cursos - recursos/Visão Computacional Guia Completo/Weights/shape_predictor_68_face_landmarks.dat')

imagem = cv2.imread('/content/drive/MyDrive/Cursos - recursos/Visão Computacional Guia Completo/Images/people2.jpg')
deteccoes = detector_face(imagem, 1)
for face in deteccoes:
  pontos = detector_pontos(imagem, face)
  for ponto in pontos.parts():
    cv2.circle(imagem, (ponto.x, ponto.y), 2, (0,255,0), 1)


  #print(pontos.parts())
  #print(len(pontos.parts()))

  l, t, r, b = face.left(), face.top(), face.right(), face.bottom()
  cv2.rectangle(imagem, (l,t), (r, b), (0,255,255), 2)
cv2_imshow(imagem)

"""## Detecção de descritores faciais"""

# Resnet: https://arxiv.org/abs/1512.03385
detector_face = dlib.get_frontal_face_detector()
detector_pontos = dlib.shape_predictor('/content/drive/MyDrive/Cursos - recursos/Visão Computacional Guia Completo/Weights/shape_predictor_68_face_landmarks.dat')
descritor_facial_extrator = dlib.face_recognition_model_v1('/content/drive/MyDrive/Cursos - recursos/Visão Computacional Guia Completo/Weights/dlib_face_recognition_resnet_model_v1.dat')

index = {}
idx = 0
descritores_faciais = None

paths = [os.path.join('/content/yalefaces/train', f) for f in os.listdir('/content/yalefaces/train')]
for path in paths:
  #print(path)
  imagem = Image.open(path).convert('RGB')
  imagem_np = np.array(imagem, 'uint8')
  deteccoes = detector_face(imagem_np, 1)
  for face in deteccoes:
    l, t, r, b = face.left(), face.top(), face.right(), face.bottom()
    cv2.rectangle(imagem_np, (l,t), (r,b), (0,0,255), 2)

    pontos = detector_pontos(imagem_np, face)
    for ponto in pontos.parts():
      cv2.circle(imagem_np, (ponto.x, ponto.y), 2, (0,255,0), 1)

    descritor_facial = descritor_facial_extrator.compute_face_descriptor(imagem_np, pontos)
    #print(type(descritor_facial))
    #print(len(descritor_facial))
    #print(descritor_facial)
    descritor_facial = [f for f in descritor_facial]
    #print(descritor_facial)
    descritor_facial = np.asarray(descritor_facial, dtype=np.float64)
    #print(descritor_facial)
    #print(descritor_facial.shape)
    descritor_facial = descritor_facial[np.newaxis, :]
    #print(descritor_facial.shape)
    #print(descritor_facial)

    if descritores_faciais is None:
      descritores_faciais = descritor_facial
    else:
      descritores_faciais = np.concatenate((descritores_faciais, descritor_facial), axis = 0)
  
    index[idx] = path
    idx += 1
  #cv2_imshow(imagem_np)

descritores_faciais.shape

descritores_faciais

index

len(index)

"""## Cálculo da distância entre as faces"""

descritores_faciais[131]

np.linalg.norm(descritores_faciais[131] - descritores_faciais[131])

np.linalg.norm(descritores_faciais[131] - descritores_faciais[130])

np.linalg.norm(descritores_faciais[131] - descritores_faciais[129])

np.linalg.norm(descritores_faciais[131] - descritores_faciais[128])

np.linalg.norm(descritores_faciais[131] - descritores_faciais[119])

np.linalg.norm(descritores_faciais[0] - descritores_faciais, axis = 1)

np.argmin(np.linalg.norm(descritores_faciais[0] - descritores_faciais[1:], axis = 1))

np.linalg.norm(descritores_faciais[0] - descritores_faciais[1:], axis = 1)[18]

"""## Detecção de faces com Dlib"""

confianca = 0.5
previsoes = []
saidas_esperadas = []

paths = [os.path.join('/content/yalefaces/test', f) for f in os.listdir('/content/yalefaces/test')]
for path in paths:
  #print(path)
  imagem = Image.open(path).convert('RGB')
  imagem_np = np.array(imagem, 'uint8')
  deteccoes = detector_face(imagem_np, 1)
  for face in deteccoes:
    pontos = detector_pontos(imagem_np, face)
    descritor_facial = descritor_facial_extrator.compute_face_descriptor(imagem_np, pontos)
    descritor_facial = [f for f in descritor_facial]
    descritor_facial = np.asarray(descritor_facial, dtype=np.float64)
    descritor_facial = descritor_facial[np.newaxis, :]

    distancias = np.linalg.norm(descritor_facial - descritores_faciais, axis = 1)
    indice_minimo = np.argmin(distancias)
    distancia_minima = distancias[indice_minimo]
    if distancia_minima <= confianca:
      nome_previsao = int(os.path.split(index[indice_minimo])[1].split('.')[0].replace('subject', ''))
    else:
      nome_previsao = 'Face não identificada'

    nome_real = int(os.path.split(path)[1].split('.')[0].replace('subject', ''))

    previsoes.append(nome_previsao)
    saidas_esperadas.append(nome_real)

    cv2.putText(imagem_np, 'Pred: ' + str(nome_previsao), (10,30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))
    cv2.putText(imagem_np, 'Exp: ' + str(nome_real), (10,50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))

  cv2_imshow(imagem_np)

previsoes = np.array(previsoes)
saidas_esperadas = np.array(saidas_esperadas)

previsoes

saidas_esperadas

from sklearn.metrics import accuracy_score
accuracy_score(saidas_esperadas, previsoes)

"""# Exercício"""

from google.colab import drive
drive.mount('/content/drive')

import zipfile
path = '/content/drive/MyDrive/Cursos - recursos/Visão Computacional Guia Completo/Datasets/jones_gabriel.zip'
zip_object = zipfile.ZipFile(file=path, mode='r')
zip_object.extractall('./')
zip_object.close()

def get_image_data():
  paths = [os.path.join('/content/jones_gabriel', f) for f in os.listdir('/content/jones_gabriel')]
  faces = []
  ids = []
  for path in paths:
    image = Image.open(path).convert('L')
    image_np = np.array(image, 'uint8')
    id = int(path.split('.')[1])
    
    ids.append(id)
    faces.append(image_np)
  
  return np.array(ids), faces

ids, faces = get_image_data()

ids

faces

lbph_classifier = cv2.face.LBPHFaceRecognizer_create()
lbph_classifier.train(faces, ids)
lbph_classifier.write('lbph_classifier.yml')

lbph_face_classifier = cv2.face.LBPHFaceRecognizer_create()
lbph_face_classifier.read('/content/lbph_classifier.yml')

paths = [os.path.join('/content/jones_gabriel', f) for f in os.listdir('/content/jones_gabriel')]
for path in paths:
  image = Image.open(path).convert('L')
  image_np = np.array(image, 'uint8')
  prediction, _ = lbph_face_classifier.predict(image_np)
  expected_output = int(path.split('.')[1])

  cv2.putText(image_np, 'Pred: ' + str(prediction), (10,30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))
  cv2.putText(image_np, 'Exp: ' + str(expected_output), (10,50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,255,0))
  cv2_imshow(image_np)